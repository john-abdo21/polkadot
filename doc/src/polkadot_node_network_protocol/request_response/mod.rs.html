<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0"><meta name="generator" content="rustdoc"><meta name="description" content="Source of the Rust file `node/network/protocol/src/request_response/mod.rs`."><meta name="keywords" content="rust, rustlang, rust-lang"><title>mod.rs - source</title><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceSerif4-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../FiraSans-Regular.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../FiraSans-Medium.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceCodePro-Regular.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceSerif4-Bold.ttf.woff2"><link rel="preload" as="font" type="font/woff2" crossorigin href="../../../SourceCodePro-Semibold.ttf.woff2"><link rel="stylesheet" href="../../../normalize.css"><link rel="stylesheet" href="../../../rustdoc.css" id="mainThemeStyle"><link rel="stylesheet" href="../../../ayu.css" disabled><link rel="stylesheet" href="../../../dark.css" disabled><link rel="stylesheet" href="../../../light.css" id="themeStyle"><script id="default-settings" ></script><script src="../../../storage.js"></script><script defer src="../../../source-script.js"></script><script defer src="../../../source-files.js"></script><script defer src="../../../main.js"></script><noscript><link rel="stylesheet" href="../../../noscript.css"></noscript><link rel="alternate icon" type="image/png" href="../../../favicon-16x16.png"><link rel="alternate icon" type="image/png" href="../../../favicon-32x32.png"><link rel="icon" type="image/svg+xml" href="../../../favicon.svg"></head><body class="rustdoc source"><!--[if lte IE 11]><div class="warning">This old browser is unsupported and will most likely display funky things.</div><![endif]--><nav class="sidebar"><a class="sidebar-logo" href="../../../polkadot_node_network_protocol/index.html"><div class="logo-container"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></div></a></nav><main><div class="width-limiter"><div class="sub-container"><a class="sub-logo-container" href="../../../polkadot_node_network_protocol/index.html"><img class="rust-logo" src="../../../rust-logo.svg" alt="logo"></a><nav class="sub"><form class="search-form"><div class="search-container"><span></span><input class="search-input" name="search" autocomplete="off" spellcheck="false" placeholder="Click or press ‘S’ to search, ‘?’ for more options…" type="search"><div id="help-button" title="help" tabindex="-1"><button type="button">?</button></div><div id="settings-menu" tabindex="-1"><a href="../../../settings.html" title="settings"><img width="22" height="22" alt="Change settings" src="../../../wheel.svg"></a></div></div></form></nav></div><section id="main-content" class="content"><div class="example-wrap"><pre class="src-line-numbers"><span id="1">1</span>
<span id="2">2</span>
<span id="3">3</span>
<span id="4">4</span>
<span id="5">5</span>
<span id="6">6</span>
<span id="7">7</span>
<span id="8">8</span>
<span id="9">9</span>
<span id="10">10</span>
<span id="11">11</span>
<span id="12">12</span>
<span id="13">13</span>
<span id="14">14</span>
<span id="15">15</span>
<span id="16">16</span>
<span id="17">17</span>
<span id="18">18</span>
<span id="19">19</span>
<span id="20">20</span>
<span id="21">21</span>
<span id="22">22</span>
<span id="23">23</span>
<span id="24">24</span>
<span id="25">25</span>
<span id="26">26</span>
<span id="27">27</span>
<span id="28">28</span>
<span id="29">29</span>
<span id="30">30</span>
<span id="31">31</span>
<span id="32">32</span>
<span id="33">33</span>
<span id="34">34</span>
<span id="35">35</span>
<span id="36">36</span>
<span id="37">37</span>
<span id="38">38</span>
<span id="39">39</span>
<span id="40">40</span>
<span id="41">41</span>
<span id="42">42</span>
<span id="43">43</span>
<span id="44">44</span>
<span id="45">45</span>
<span id="46">46</span>
<span id="47">47</span>
<span id="48">48</span>
<span id="49">49</span>
<span id="50">50</span>
<span id="51">51</span>
<span id="52">52</span>
<span id="53">53</span>
<span id="54">54</span>
<span id="55">55</span>
<span id="56">56</span>
<span id="57">57</span>
<span id="58">58</span>
<span id="59">59</span>
<span id="60">60</span>
<span id="61">61</span>
<span id="62">62</span>
<span id="63">63</span>
<span id="64">64</span>
<span id="65">65</span>
<span id="66">66</span>
<span id="67">67</span>
<span id="68">68</span>
<span id="69">69</span>
<span id="70">70</span>
<span id="71">71</span>
<span id="72">72</span>
<span id="73">73</span>
<span id="74">74</span>
<span id="75">75</span>
<span id="76">76</span>
<span id="77">77</span>
<span id="78">78</span>
<span id="79">79</span>
<span id="80">80</span>
<span id="81">81</span>
<span id="82">82</span>
<span id="83">83</span>
<span id="84">84</span>
<span id="85">85</span>
<span id="86">86</span>
<span id="87">87</span>
<span id="88">88</span>
<span id="89">89</span>
<span id="90">90</span>
<span id="91">91</span>
<span id="92">92</span>
<span id="93">93</span>
<span id="94">94</span>
<span id="95">95</span>
<span id="96">96</span>
<span id="97">97</span>
<span id="98">98</span>
<span id="99">99</span>
<span id="100">100</span>
<span id="101">101</span>
<span id="102">102</span>
<span id="103">103</span>
<span id="104">104</span>
<span id="105">105</span>
<span id="106">106</span>
<span id="107">107</span>
<span id="108">108</span>
<span id="109">109</span>
<span id="110">110</span>
<span id="111">111</span>
<span id="112">112</span>
<span id="113">113</span>
<span id="114">114</span>
<span id="115">115</span>
<span id="116">116</span>
<span id="117">117</span>
<span id="118">118</span>
<span id="119">119</span>
<span id="120">120</span>
<span id="121">121</span>
<span id="122">122</span>
<span id="123">123</span>
<span id="124">124</span>
<span id="125">125</span>
<span id="126">126</span>
<span id="127">127</span>
<span id="128">128</span>
<span id="129">129</span>
<span id="130">130</span>
<span id="131">131</span>
<span id="132">132</span>
<span id="133">133</span>
<span id="134">134</span>
<span id="135">135</span>
<span id="136">136</span>
<span id="137">137</span>
<span id="138">138</span>
<span id="139">139</span>
<span id="140">140</span>
<span id="141">141</span>
<span id="142">142</span>
<span id="143">143</span>
<span id="144">144</span>
<span id="145">145</span>
<span id="146">146</span>
<span id="147">147</span>
<span id="148">148</span>
<span id="149">149</span>
<span id="150">150</span>
<span id="151">151</span>
<span id="152">152</span>
<span id="153">153</span>
<span id="154">154</span>
<span id="155">155</span>
<span id="156">156</span>
<span id="157">157</span>
<span id="158">158</span>
<span id="159">159</span>
<span id="160">160</span>
<span id="161">161</span>
<span id="162">162</span>
<span id="163">163</span>
<span id="164">164</span>
<span id="165">165</span>
<span id="166">166</span>
<span id="167">167</span>
<span id="168">168</span>
<span id="169">169</span>
<span id="170">170</span>
<span id="171">171</span>
<span id="172">172</span>
<span id="173">173</span>
<span id="174">174</span>
<span id="175">175</span>
<span id="176">176</span>
<span id="177">177</span>
<span id="178">178</span>
<span id="179">179</span>
<span id="180">180</span>
<span id="181">181</span>
<span id="182">182</span>
<span id="183">183</span>
<span id="184">184</span>
<span id="185">185</span>
<span id="186">186</span>
<span id="187">187</span>
<span id="188">188</span>
<span id="189">189</span>
<span id="190">190</span>
<span id="191">191</span>
<span id="192">192</span>
<span id="193">193</span>
<span id="194">194</span>
<span id="195">195</span>
<span id="196">196</span>
<span id="197">197</span>
<span id="198">198</span>
<span id="199">199</span>
<span id="200">200</span>
<span id="201">201</span>
<span id="202">202</span>
<span id="203">203</span>
<span id="204">204</span>
<span id="205">205</span>
<span id="206">206</span>
<span id="207">207</span>
<span id="208">208</span>
<span id="209">209</span>
<span id="210">210</span>
<span id="211">211</span>
<span id="212">212</span>
<span id="213">213</span>
<span id="214">214</span>
<span id="215">215</span>
<span id="216">216</span>
<span id="217">217</span>
<span id="218">218</span>
<span id="219">219</span>
<span id="220">220</span>
<span id="221">221</span>
<span id="222">222</span>
<span id="223">223</span>
<span id="224">224</span>
<span id="225">225</span>
<span id="226">226</span>
<span id="227">227</span>
<span id="228">228</span>
<span id="229">229</span>
<span id="230">230</span>
<span id="231">231</span>
<span id="232">232</span>
<span id="233">233</span>
<span id="234">234</span>
<span id="235">235</span>
<span id="236">236</span>
<span id="237">237</span>
<span id="238">238</span>
<span id="239">239</span>
<span id="240">240</span>
<span id="241">241</span>
<span id="242">242</span>
<span id="243">243</span>
<span id="244">244</span>
<span id="245">245</span>
<span id="246">246</span>
<span id="247">247</span>
<span id="248">248</span>
<span id="249">249</span>
<span id="250">250</span>
<span id="251">251</span>
<span id="252">252</span>
<span id="253">253</span>
<span id="254">254</span>
<span id="255">255</span>
<span id="256">256</span>
<span id="257">257</span>
<span id="258">258</span>
<span id="259">259</span>
<span id="260">260</span>
<span id="261">261</span>
<span id="262">262</span>
<span id="263">263</span>
<span id="264">264</span>
<span id="265">265</span>
<span id="266">266</span>
<span id="267">267</span>
<span id="268">268</span>
<span id="269">269</span>
<span id="270">270</span>
<span id="271">271</span>
<span id="272">272</span>
<span id="273">273</span>
<span id="274">274</span>
<span id="275">275</span>
<span id="276">276</span>
<span id="277">277</span>
<span id="278">278</span>
<span id="279">279</span>
<span id="280">280</span>
<span id="281">281</span>
<span id="282">282</span>
<span id="283">283</span>
<span id="284">284</span>
<span id="285">285</span>
<span id="286">286</span>
<span id="287">287</span>
<span id="288">288</span>
<span id="289">289</span>
<span id="290">290</span>
<span id="291">291</span>
<span id="292">292</span>
<span id="293">293</span>
<span id="294">294</span>
<span id="295">295</span>
<span id="296">296</span>
<span id="297">297</span>
<span id="298">298</span>
<span id="299">299</span>
<span id="300">300</span>
<span id="301">301</span>
<span id="302">302</span>
<span id="303">303</span>
<span id="304">304</span>
<span id="305">305</span>
<span id="306">306</span>
<span id="307">307</span>
<span id="308">308</span>
<span id="309">309</span>
<span id="310">310</span>
<span id="311">311</span>
<span id="312">312</span>
<span id="313">313</span>
<span id="314">314</span>
<span id="315">315</span>
<span id="316">316</span>
<span id="317">317</span>
<span id="318">318</span>
<span id="319">319</span>
<span id="320">320</span>
<span id="321">321</span>
<span id="322">322</span>
<span id="323">323</span>
<span id="324">324</span>
<span id="325">325</span>
</pre><pre class="rust"><code><span class="comment">// Copyright 2021 Parity Technologies (UK) Ltd.
// This file is part of Polkadot.

// Polkadot is free software: you can redistribute it and/or modify
// it under the terms of the GNU General Public License as published by
// the Free Software Foundation, either version 3 of the License, or
// (at your option) any later version.

// Polkadot is distributed in the hope that it will be useful,
// but WITHOUT ANY WARRANTY; without even the implied warranty of
// MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
// GNU General Public License for more details.

// You should have received a copy of the GNU General Public License
// along with Polkadot.  If not, see &lt;http://www.gnu.org/licenses/&gt;.

</span><span class="doccomment">//! Overview over request/responses as used in `Polkadot`.
//!
//! `enum Protocol` .... List of all supported protocols.
//!
//! `enum Requests`  .... List of all supported requests, each entry matches one in protocols, but
//! has the actual request as payload.
//!
//! `struct IncomingRequest` .... wrapper for incoming requests, containing a sender for sending
//! responses.
//!
//! `struct OutgoingRequest` .... wrapper for outgoing requests, containing a sender used by the
//! networking code for delivering responses/delivery errors.
//!
//! `trait IsRequest` .... A trait describing a particular request. It is used for gathering meta
//! data, like what is the corresponding response type.
//!
//!  Versioned (v1 module): The actual requests and responses as sent over the network.

</span><span class="kw">use </span>std::{collections::HashMap, time::Duration, u64};

<span class="kw">use </span>futures::channel::mpsc;
<span class="kw">use </span>polkadot_primitives::v2::{MAX_CODE_SIZE, MAX_POV_SIZE};
<span class="kw">use </span>strum::{EnumIter, IntoEnumIterator};

<span class="kw">pub use </span>sc_network::{config <span class="kw">as </span>network, config::RequestResponseConfig, ProtocolName};

<span class="doccomment">/// Everything related to handling of incoming requests.
</span><span class="kw">pub mod </span>incoming;
<span class="doccomment">/// Everything related to handling of outgoing requests.
</span><span class="kw">pub mod </span>outgoing;

<span class="kw">pub use </span>incoming::{IncomingRequest, IncomingRequestReceiver};

<span class="kw">pub use </span>outgoing::{OutgoingRequest, OutgoingResult, Recipient, Requests, ResponseSender};

<span class="comment">///// Multiplexer for incoming requests.
// pub mod multiplexer;

</span><span class="doccomment">/// Actual versioned requests and responses, that are sent over the wire.
</span><span class="kw">pub mod </span>v1;

<span class="doccomment">/// A protocol per subsystem seems to make the most sense, this way we don&#39;t need any dispatching
/// within protocols.
</span><span class="attribute">#[derive(Copy, Clone, Debug, Hash, PartialEq, Eq, EnumIter)]
</span><span class="kw">pub enum </span>Protocol {
	<span class="doccomment">/// Protocol for chunk fetching, used by availability distribution and availability recovery.
	</span>ChunkFetchingV1,
	<span class="doccomment">/// Protocol for fetching collations from collators.
	</span>CollationFetchingV1,
	<span class="doccomment">/// Protocol for fetching seconded PoVs from validators of the same group.
	</span>PoVFetchingV1,
	<span class="doccomment">/// Protocol for fetching available data.
	</span>AvailableDataFetchingV1,
	<span class="doccomment">/// Fetching of statements that are too large for gossip.
	</span>StatementFetchingV1,
	<span class="doccomment">/// Sending of dispute statements with application level confirmations.
	</span>DisputeSendingV1,
}

<span class="doccomment">/// Minimum bandwidth we expect for validators - 500Mbit/s is the recommendation, so approximately
/// 50MB per second:
</span><span class="kw">const </span>MIN_BANDWIDTH_BYTES: u64 = <span class="number">50 </span>* <span class="number">1024 </span>* <span class="number">1024</span>;

<span class="doccomment">/// Default request timeout in seconds.
///
/// When decreasing this value, take into account that the very first request might need to open a
/// connection, which can be slow. If this causes problems, we should ensure connectivity via peer
/// sets.
</span><span class="attribute">#[allow(dead_code)]
</span><span class="kw">const </span>DEFAULT_REQUEST_TIMEOUT: Duration = Duration::from_secs(<span class="number">3</span>);

<span class="doccomment">/// Request timeout where we can assume the connection is already open (e.g. we have peers in a
/// peer set as well).
</span><span class="kw">const </span>DEFAULT_REQUEST_TIMEOUT_CONNECTED: Duration = Duration::from_secs(<span class="number">1</span>);

<span class="doccomment">/// Timeout for requesting availability chunks.
</span><span class="kw">pub const </span>CHUNK_REQUEST_TIMEOUT: Duration = DEFAULT_REQUEST_TIMEOUT_CONNECTED;

<span class="doccomment">/// This timeout is based on what seems sensible from a time budget perspective, considering 6
/// second block time. This is going to be tough, if we have multiple forks and large PoVs, but we
/// only have so much time.
</span><span class="kw">const </span>POV_REQUEST_TIMEOUT_CONNECTED: Duration = Duration::from_millis(<span class="number">1200</span>);

<span class="doccomment">/// We want timeout statement requests fast, so we don&#39;t waste time on slow nodes. Responders will
/// try their best to either serve within that timeout or return an error immediately. (We need to
/// fit statement distribution within a block of 6 seconds.)
</span><span class="kw">const </span>STATEMENTS_TIMEOUT: Duration = Duration::from_secs(<span class="number">1</span>);

<span class="doccomment">/// We don&#39;t want a slow peer to slow down all the others, at the same time we want to get out the
/// data quickly in full to at least some peers (as this will reduce load on us as they then can
/// start serving the data). So this value is a tradeoff. 3 seems to be sensible. So we would need
/// to have 3 slow nodes connected, to delay transfer for others by `STATEMENTS_TIMEOUT`.
</span><span class="kw">pub const </span>MAX_PARALLEL_STATEMENT_REQUESTS: u32 = <span class="number">3</span>;

<span class="doccomment">/// Response size limit for responses of POV like data.
///
/// This is larger than `MAX_POV_SIZE` to account for protocol overhead and for additional data in
/// `CollationFetchingV1` or `AvailableDataFetchingV1` for example. We try to err on larger limits here
/// as a too large limit only allows an attacker to waste our bandwidth some more, a too low limit
/// might have more severe effects.
</span><span class="kw">const </span>POV_RESPONSE_SIZE: u64 = MAX_POV_SIZE <span class="kw">as </span>u64 + <span class="number">10_000</span>;

<span class="doccomment">/// Maximum response sizes for `StatementFetchingV1`.
///
/// This is `MAX_CODE_SIZE` plus some additional space for protocol overhead.
</span><span class="kw">const </span>STATEMENT_RESPONSE_SIZE: u64 = MAX_CODE_SIZE <span class="kw">as </span>u64 + <span class="number">10_000</span>;

<span class="doccomment">/// We can have relative large timeouts here, there is no value of hitting a
/// timeout as we want to get statements through to each node in any case.
</span><span class="kw">pub const </span>DISPUTE_REQUEST_TIMEOUT: Duration = Duration::from_secs(<span class="number">12</span>);

<span class="kw">impl </span>Protocol {
	<span class="doccomment">/// Get a configuration for a given Request response protocol.
	///
	/// Returns a receiver for messages received on this protocol and the requested
	/// `ProtocolConfig`.
	</span><span class="kw">pub fn </span>get_config(
		<span class="self">self</span>,
		req_protocol_names: <span class="kw-2">&amp;</span>ReqProtocolNames,
	) -&gt; (mpsc::Receiver&lt;network::IncomingRequest&gt;, RequestResponseConfig) {
		<span class="kw">let </span>name = req_protocol_names.get_name(<span class="self">self</span>);
		<span class="kw">let </span>fallback_names = <span class="self">self</span>.get_fallback_names();
		<span class="kw">let </span>(tx, rx) = mpsc::channel(<span class="self">self</span>.get_channel_size());
		<span class="kw">let </span>cfg = <span class="kw">match </span><span class="self">self </span>{
			Protocol::ChunkFetchingV1 =&gt; RequestResponseConfig {
				name,
				fallback_names,
				max_request_size: <span class="number">1_000</span>,
				max_response_size: POV_RESPONSE_SIZE <span class="kw">as </span>u64 * <span class="number">3</span>,
				<span class="comment">// We are connected to all validators:
				</span>request_timeout: CHUNK_REQUEST_TIMEOUT,
				inbound_queue: <span class="prelude-val">Some</span>(tx),
			},
			Protocol::CollationFetchingV1 =&gt; RequestResponseConfig {
				name,
				fallback_names,
				max_request_size: <span class="number">1_000</span>,
				max_response_size: POV_RESPONSE_SIZE,
				<span class="comment">// Taken from initial implementation in collator protocol:
				</span>request_timeout: POV_REQUEST_TIMEOUT_CONNECTED,
				inbound_queue: <span class="prelude-val">Some</span>(tx),
			},
			Protocol::PoVFetchingV1 =&gt; RequestResponseConfig {
				name,
				fallback_names,
				max_request_size: <span class="number">1_000</span>,
				max_response_size: POV_RESPONSE_SIZE,
				request_timeout: POV_REQUEST_TIMEOUT_CONNECTED,
				inbound_queue: <span class="prelude-val">Some</span>(tx),
			},
			Protocol::AvailableDataFetchingV1 =&gt; RequestResponseConfig {
				name,
				fallback_names,
				max_request_size: <span class="number">1_000</span>,
				<span class="comment">// Available data size is dominated by the PoV size.
				</span>max_response_size: POV_RESPONSE_SIZE,
				request_timeout: POV_REQUEST_TIMEOUT_CONNECTED,
				inbound_queue: <span class="prelude-val">Some</span>(tx),
			},
			Protocol::StatementFetchingV1 =&gt; RequestResponseConfig {
				name,
				fallback_names,
				max_request_size: <span class="number">1_000</span>,
				<span class="comment">// Available data size is dominated code size.
				</span>max_response_size: STATEMENT_RESPONSE_SIZE,
				<span class="comment">// We need statement fetching to be fast and will try our best at the responding
				// side to answer requests within that timeout, assuming a bandwidth of 500Mbit/s
				// - which is the recommended minimum bandwidth for nodes on Kusama as of April
				// 2021.
				// Responders will reject requests, if it is unlikely they can serve them within
				// the timeout, so the requester can immediately try another node, instead of
				// waiting for timeout on an overloaded node.  Fetches from slow nodes will likely
				// fail, but this is desired, so we can quickly move on to a faster one - we should
				// also decrease its reputation.
				</span>request_timeout: Duration::from_secs(<span class="number">1</span>),
				inbound_queue: <span class="prelude-val">Some</span>(tx),
			},
			Protocol::DisputeSendingV1 =&gt; RequestResponseConfig {
				name,
				fallback_names,
				max_request_size: <span class="number">1_000</span>,
				<span class="doccomment">/// Responses are just confirmation, in essence not even a bit. So 100 seems
				/// plenty.
				</span>max_response_size: <span class="number">100</span>,
				request_timeout: DISPUTE_REQUEST_TIMEOUT,
				inbound_queue: <span class="prelude-val">Some</span>(tx),
			},
		};
		(rx, cfg)
	}

	<span class="comment">// Channel sizes for the supported protocols.
	</span><span class="kw">fn </span>get_channel_size(<span class="self">self</span>) -&gt; usize {
		<span class="kw">match </span><span class="self">self </span>{
			<span class="comment">// Hundreds of validators will start requesting their chunks once they see a candidate
			// awaiting availability on chain. Given that they will see that block at different
			// times (due to network delays), 100 seems big enough to accomodate for &quot;bursts&quot;,
			// assuming we can service requests relatively quickly, which would need to be measured
			// as well.
			</span>Protocol::ChunkFetchingV1 =&gt; <span class="number">100</span>,
			<span class="comment">// 10 seems reasonable, considering group sizes of max 10 validators.
			</span>Protocol::CollationFetchingV1 =&gt; <span class="number">10</span>,
			<span class="comment">// 10 seems reasonable, considering group sizes of max 10 validators.
			</span>Protocol::PoVFetchingV1 =&gt; <span class="number">10</span>,
			<span class="comment">// Validators are constantly self-selecting to request available data which may lead
			// to constant load and occasional burstiness.
			</span>Protocol::AvailableDataFetchingV1 =&gt; <span class="number">100</span>,
			<span class="comment">// Our queue size approximation is how many blocks of the size of
			// a runtime we can transfer within a statements timeout, minus the requests we handle
			// in parallel.
			</span>Protocol::StatementFetchingV1 =&gt; {
				<span class="comment">// We assume we can utilize up to 70% of the available bandwidth for statements.
				// This is just a guess/estimate, with the following considerations: If we are
				// faster than that, queue size will stay low anyway, even if not - requesters will
				// get an immediate error, but if we are slower, requesters will run in a timeout -
				// wasting precious time.
				</span><span class="kw">let </span>available_bandwidth = <span class="number">7 </span>* MIN_BANDWIDTH_BYTES / <span class="number">10</span>;
				<span class="kw">let </span>size = u64::saturating_sub(
					STATEMENTS_TIMEOUT.as_millis() <span class="kw">as </span>u64 * available_bandwidth /
						(<span class="number">1000 </span>* MAX_CODE_SIZE <span class="kw">as </span>u64),
					MAX_PARALLEL_STATEMENT_REQUESTS <span class="kw">as </span>u64,
				);
				<span class="macro">debug_assert!</span>(
					size &gt; <span class="number">0</span>,
					<span class="string">&quot;We should have a channel size greater zero, otherwise we won&#39;t accept any requests.&quot;
				</span>);
				size <span class="kw">as </span>usize
			},
			<span class="comment">// Incoming requests can get bursty, we should also be able to handle them fast on
			// average, so something in the ballpark of 100 should be fine. Nodes will retry on
			// failure, so having a good value here is mostly about performance tuning.
			</span>Protocol::DisputeSendingV1 =&gt; <span class="number">100</span>,
		}
	}

	<span class="doccomment">/// Fallback protocol names of this protocol, as understood by substrate networking.
	</span><span class="kw">fn </span>get_fallback_names(<span class="self">self</span>) -&gt; Vec&lt;ProtocolName&gt; {
		std::iter::once(<span class="self">self</span>.get_legacy_name().into()).collect()
	}

	<span class="doccomment">/// Legacy protocol name associated with each peer set.
	</span><span class="kw">const fn </span>get_legacy_name(<span class="self">self</span>) -&gt; <span class="kw-2">&amp;</span><span class="lifetime">&#39;static </span>str {
		<span class="kw">match </span><span class="self">self </span>{
			Protocol::ChunkFetchingV1 =&gt; <span class="string">&quot;/polkadot/req_chunk/1&quot;</span>,
			Protocol::CollationFetchingV1 =&gt; <span class="string">&quot;/polkadot/req_collation/1&quot;</span>,
			Protocol::PoVFetchingV1 =&gt; <span class="string">&quot;/polkadot/req_pov/1&quot;</span>,
			Protocol::AvailableDataFetchingV1 =&gt; <span class="string">&quot;/polkadot/req_available_data/1&quot;</span>,
			Protocol::StatementFetchingV1 =&gt; <span class="string">&quot;/polkadot/req_statement/1&quot;</span>,
			Protocol::DisputeSendingV1 =&gt; <span class="string">&quot;/polkadot/send_dispute/1&quot;</span>,
		}
	}
}

<span class="doccomment">/// Common properties of any `Request`.
</span><span class="kw">pub trait </span>IsRequest {
	<span class="doccomment">/// Each request has a corresponding `Response`.
	</span><span class="kw">type </span>Response;

	<span class="doccomment">/// What protocol this `Request` implements.
	</span><span class="kw">const </span>PROTOCOL: Protocol;
}

<span class="doccomment">/// Type for getting on the wire [`Protocol`] names using genesis hash &amp; fork id.
</span><span class="kw">pub struct </span>ReqProtocolNames {
	names: HashMap&lt;Protocol, ProtocolName&gt;,
}

<span class="kw">impl </span>ReqProtocolNames {
	<span class="doccomment">/// Construct [`ReqProtocolNames`] from `genesis_hash` and `fork_id`.
	</span><span class="kw">pub fn </span>new&lt;Hash: AsRef&lt;[u8]&gt;&gt;(genesis_hash: Hash, fork_id: <span class="prelude-ty">Option</span>&lt;<span class="kw-2">&amp;</span>str&gt;) -&gt; <span class="self">Self </span>{
		<span class="kw">let </span><span class="kw-2">mut </span>names = HashMap::new();
		<span class="kw">for </span>protocol <span class="kw">in </span>Protocol::iter() {
			names.insert(protocol, <span class="self">Self</span>::generate_name(protocol, <span class="kw-2">&amp;</span>genesis_hash, fork_id));
		}
		<span class="self">Self </span>{ names }
	}

	<span class="doccomment">/// Get on the wire [`Protocol`] name.
	</span><span class="kw">pub fn </span>get_name(<span class="kw-2">&amp;</span><span class="self">self</span>, protocol: Protocol) -&gt; ProtocolName {
		<span class="self">self</span>.names
			.get(<span class="kw-2">&amp;</span>protocol)
			.expect(<span class="string">&quot;All `Protocol` enum variants are added above via `strum`; qed&quot;</span>)
			.clone()
	}

	<span class="doccomment">/// Protocol name of this protocol based on `genesis_hash` and `fork_id`.
	</span><span class="kw">fn </span>generate_name&lt;Hash: AsRef&lt;[u8]&gt;&gt;(
		protocol: Protocol,
		genesis_hash: <span class="kw-2">&amp;</span>Hash,
		fork_id: <span class="prelude-ty">Option</span>&lt;<span class="kw-2">&amp;</span>str&gt;,
	) -&gt; ProtocolName {
		<span class="kw">let </span>prefix = <span class="kw">if let </span><span class="prelude-val">Some</span>(fork_id) = fork_id {
			<span class="macro">format!</span>(<span class="string">&quot;/{}/{}&quot;</span>, hex::encode(genesis_hash), fork_id)
		} <span class="kw">else </span>{
			<span class="macro">format!</span>(<span class="string">&quot;/{}&quot;</span>, hex::encode(genesis_hash))
		};

		<span class="kw">let </span>short_name = <span class="kw">match </span>protocol {
			Protocol::ChunkFetchingV1 =&gt; <span class="string">&quot;/req_chunk/1&quot;</span>,
			Protocol::CollationFetchingV1 =&gt; <span class="string">&quot;/req_collation/1&quot;</span>,
			Protocol::PoVFetchingV1 =&gt; <span class="string">&quot;/req_pov/1&quot;</span>,
			Protocol::AvailableDataFetchingV1 =&gt; <span class="string">&quot;/req_available_data/1&quot;</span>,
			Protocol::StatementFetchingV1 =&gt; <span class="string">&quot;/req_statement/1&quot;</span>,
			Protocol::DisputeSendingV1 =&gt; <span class="string">&quot;/send_dispute/1&quot;</span>,
		};

		<span class="macro">format!</span>(<span class="string">&quot;{}{}&quot;</span>, prefix, short_name).into()
	}
}
</code></pre></div>
</section></div></main><div id="rustdoc-vars" data-root-path="../../../" data-current-crate="polkadot_node_network_protocol" data-themes="ayu,dark,light" data-resource-suffix="" data-rustdoc-version="1.66.0-nightly (81f391930 2022-10-09)" ></div></body></html>